end  = Sys.time()
print(end - start)
# Compute the error existing between flows
preds = anderson(res.station$par[1:nb_params])
flows.error = abs(as.numeric(out.flows[1,]) - preds)
print(paste('flow error', flows.error)) # The errors commited on the four flows
#install.packages('dfoptim')
library(dfoptim)
# Paths to update on your machine:
# data.folder: Where to look for the outflows to which model outputs will be compared
# res.folder: Where to write the PGE/ CFs parameters estimates
# code.folder: The path to the Anderson model
data.folder = "C:/Users/rfuchs/Documents/GitHub/CarbonPump/optimisation"
res.folder = "C:/Users/rfuchs/Documents/These/Oceano/carbon_pump_abc/opt/simus/20211401/"
code.folder = "C:/Users/rfuchs/Documents/GitHub/CarbonPump/optimisation"
source(file.path(code.folder, 'model.R'))
#======================================
# Utilities definition
#======================================
# The weighted euclidian distance :
euc.dist <- function(x1, x2, w = 1) sqrt(rowSums((w *(x1 - x2)) ^ 2))
# The labels used for outputing
anderson_labels_txt = c('POC', 'DOC', 'psi', 'wA', 'wFL', 'alpha', 'CF_A',
'CF_FL')
# Compute the normalized error between the predicted out flows and the actual outflows
pred.error <- function(X){
models.params = X[1:8] # The 8 first parameters are the input parameters (see line 20 for the names)
out.flows = as.numeric(X[9:12]) # The four last parameters are the values of the outflows
pred = anderson(as.numeric(models.params))
w = 1 / as.numeric(out.flows) # Weight by the inverse of the flows to make all outflows comparable
d = euc.dist(matrix(pred,1), matrix(out.flows,1), w)
d
} # Watch out, the number of parameters is hard-coded for the moment in this function...
#=========================================
# Data handling
#=========================================
nb_params = length(anderson_labels_txt) # The number of parameters to estimate
nb_fixed_entries = length(c('poc', 'doc')) # The in situ poc and doc measures
labels = anderson_labels_txt[(nb_fixed_entries + 1):nb_params]
# Fetch the observed outflows
flows = read.csv(file.path(data.folder, 'out_flows_4flows_PAP.csv'), sep = ';')
nb_stats = length(out.flows)
names(flows) = c('Cruise', 'Station', 'Depths',
'POC net', 'DOC net', 'prod non sinking',
'prod sinking', 'resp sinking', 'resp zoo')
out.flows = flows[,c('prod non sinking', 'prod sinking',
'resp sinking', 'resp zoo')]
# Get the poc and doc flows
poc = flows[1,'POC net']
doc = flows[1,'DOC net']
# Get the sample location meta data
cruise = flows[1,'Cruise']
station = flows[1,'Station']
station = gsub('/', '-', station)
#=========================================
# Optimisation process
#=========================================
# The initial parameters values to launch the algorithm
# They were chosen to be the ones in the Anderson and Tang or in the Giering et al. paper
starting.values = c(c(poc, doc, 0.75, 0.02, 0.08, 0.5, 0.44, 0.44), out.flows[1,])
starting.values = as.numeric(starting.values)
# Lower/upper bounds contraints for each parameter.
# The optimisation algorithm needs a non-null range for all params
# => Use an epsilon to have a [poc - epsilon, poc + epsilon] range (same for the doc)
epsilon = 1E-8
lb = c(c(poc - epsilon, doc - epsilon), rep(0, nb_params - nb_fixed_entries), as.numeric(out.flows[1,]) - epsilon)
lb = as.numeric(lb)
ub = c(c(poc + epsilon, doc + epsilon, 1, 0.1, 0.1, 1, 6, 6), as.numeric(out.flows[1,]) + epsilon) # Lower bounds contraints for each parameter
ub = as.numeric(ub)
# Performs a gradient-free optimisation
# The goal is to minimize the distance existing between the measured
# outflows and their model counterparts
start = Sys.time()
res.station = nmkb(par = starting.values, fn = pred.error, lower=lb, upper=ub)
end  = Sys.time()
print(end - start)
# Compute the error existing between flows
preds = anderson(res.station$par[1:nb_params])
flows.error = abs(as.numeric(out.flows[1,]) - preds)
print(paste('flow error', flows.error)) # The errors commited on the four flows
#install.packages('dfoptim')
library(dfoptim)
data.folder = "C:/Users/rfuchs/Documents/GitHub/CarbonPump/optimisation"
res.folder = "C:/Users/rfuchs/Documents/These/Oceano/carbon_pump_abc/opt/simus/20211401/"
code.folder = "C:/Users/rfuchs/Documents/GitHub/CarbonPump/optimisation"
source(file.path(code.folder, 'model.R'))
# The weighted euclidian distance :
euc.dist <- function(x1, x2, w = 1) sqrt(rowSums((w *(x1 - x2)) ^ 2))
# The labels used for outputing
anderson_labels_txt = c('POC', 'DOC', 'psi', 'wA', 'wFL', 'alpha', 'CF_A',
'CF_FL')
# Compute the normalized error between the predicted out flows and the actual outflows
pred.error <- function(X){
models.params = X[1:8] # The 8 first parameters are the input parameters (see line 20 for the names)
out.flows = as.numeric(X[9:12]) # The four last parameters are the values of the outflows
pred = anderson(as.numeric(models.params))
w = 1 / as.numeric(out.flows) # Weight by the inverse of the flows to make all outflows comparable
d = euc.dist(matrix(pred,1), matrix(out.flows,1), w)
d
} # Watch out, the number of parameters is hard-coded for the moment in this function...
nb_params = length(anderson_labels_txt) # The number of parameters to estimate
nb_fixed_entries = length(c('poc', 'doc')) # The in situ poc and doc measures
labels = anderson_labels_txt[(nb_fixed_entries + 1):nb_params]
# Fetch the observed outflows
flows = read.csv(file.path(data.folder, 'out_flows_4flows_PAP.csv'), sep = ';')
nb_stats = length(out.flows)
names(flows) = c('Cruise', 'Station', 'Depths',
'POC net', 'DOC net', 'prod non sinking',
'prod sinking', 'resp sinking', 'resp zoo')
out.flows = flows[,c('prod non sinking', 'prod sinking',
'resp sinking', 'resp zoo')]
# Get the poc and doc flows
poc = flows[1,'POC net']
doc = flows[1,'DOC net']
# Get the sample location meta data
cruise = flows[1,'Cruise']
station = flows[1,'Station']
station = gsub('/', '-', station)
# The initial parameters values to launch the algorithm
# They were chosen to be the ones in the Anderson and Tang or in the Giering et al. paper
starting.values = c(c(poc, doc, 0.75, 0.02, 0.08, 0.5, 0.44, 0.44), out.flows[1,])
starting.values = as.numeric(starting.values)
# Lower/upper bounds contraints for each parameter.
# The optimisation algorithm needs a non-null range for all params
# => Use an epsilon to have a [poc - epsilon, poc + epsilon] range (same for the doc)
epsilon = 1E-8
lb = c(c(poc - epsilon, doc - epsilon), rep(0, nb_params - nb_fixed_entries), as.numeric(out.flows[1,]) - epsilon)
lb = as.numeric(lb)
ub = c(c(poc + epsilon, doc + epsilon, 1, 0.1, 0.1, 1, 6, 6), as.numeric(out.flows[1,]) + epsilon) # Lower bounds contraints for each parameter
ub = as.numeric(ub)
# Performs a gradient-free optimisation
# The goal is to minimize the distance existing between the measured
# outflows and their model counterparts
start = Sys.time()
res.station = nmkb(par = starting.values, fn = pred.error, lower=lb, upper=ub)
end  = Sys.time()
print(end - start)
#install.packages('dfoptim')
library(dfoptim)
# Paths to update on your machine:
# data.folder: Where to look for the outflows to which model outputs will be compared
# res.folder: Where to write the PGE/ CFs parameters estimates
# code.folder: The path to the Anderson model
data.folder = "C:/Users/rfuchs/Documents/GitHub/CarbonPump/optimisation"
res.folder = "C:/Users/rfuchs/Documents/These/Oceano/carbon_pump_abc/opt/simus/20211401/"
code.folder = "C:/Users/rfuchs/Documents/GitHub/CarbonPump/optimisation"
source(file.path(code.folder, 'model.R'))
#======================================
# Utilities definition
#======================================
# The weighted euclidian distance :
euc.dist <- function(x1, x2, w = 1) sqrt(rowSums((w *(x1 - x2)) ^ 2))
# The labels used for outputing
anderson_labels_txt = c('POC', 'DOC', 'psi', 'wA', 'wFL', 'alpha', 'CF_A',
'CF_FL')
# Compute the normalized error between the predicted out flows and the actual outflows
pred.error <- function(X){
models.params = X[1:8] # The 8 first parameters are the input parameters (see line 20 for the names)
out.flows = as.numeric(X[9:12]) # The four last parameters are the values of the outflows
pred = anderson(as.numeric(models.params))
w = 1 / as.numeric(out.flows) # Weight by the inverse of the flows to make all outflows comparable
d = euc.dist(matrix(pred,1), matrix(out.flows,1), w)
d
} # Watch out, the number of parameters is hard-coded for the moment in this function...
#=========================================
# Data handling
#=========================================
nb_params = length(anderson_labels_txt) # The number of parameters to estimate
nb_fixed_entries = length(c('poc', 'doc')) # The in situ poc and doc measures
labels = anderson_labels_txt[(nb_fixed_entries + 1):nb_params]
# Fetch the observed outflows
flows = read.csv(file.path(data.folder, 'out_flows_4flows_PAP.csv'), sep = ';')
nb_stats = length(out.flows)
names(flows) = c('Cruise', 'Station', 'Depths',
'POC net', 'DOC net', 'prod non sinking',
'prod sinking', 'resp sinking', 'resp zoo')
out.flows = flows[,c('prod non sinking', 'prod sinking',
'resp sinking', 'resp zoo')]
# Get the poc and doc flows
poc = flows[1,'POC net']
doc = flows[1,'DOC net']
# Get the sample location meta data
cruise = flows[1,'Cruise']
station = flows[1,'Station']
station = gsub('/', '-', station)
#=========================================
# Optimisation process
#=========================================
# The initial parameters values to launch the algorithm
# They were chosen to be the ones in the Anderson and Tang or in the Giering et al. paper
starting.values = c(c(poc, doc, 0.75, 0.02, 0.08, 0.5, 0.44, 0.44), out.flows[1,])
starting.values = as.numeric(starting.values)
# Lower/upper bounds contraints for each parameter.
# The optimisation algorithm needs a non-null range for all params
# => Use an epsilon to have a [poc - epsilon, poc + epsilon] range (same for the doc)
epsilon = 1E-8
lb = c(c(poc - epsilon, doc - epsilon), rep(0, nb_params - nb_fixed_entries), as.numeric(out.flows[1,]) - epsilon)
lb = as.numeric(lb)
ub = c(c(poc + epsilon, doc + epsilon, 1, 0.1, 0.1, 1, 6, 6), as.numeric(out.flows[1,]) + epsilon) # Lower bounds contraints for each parameter
ub = as.numeric(ub)
# Performs a gradient-free optimisation
# The goal is to minimize the distance existing between the measured
# outflows and their model counterparts
start = Sys.time()
res.station = nmkb(par = starting.values, fn = pred.error, lower=lb, upper=ub)
end  = Sys.time()
print(end - start)
res.station
res.station$par[(nb_fixed_entries + 1):nb_params]
best.params.values = matrix(best.params.values, 1, nb_params - nb_fixed_entries)
nb_params - nb_fixed_entries
unif()
runif()
runif(1)
runif(1)
runif(1)
out.flows[1,]
# The initial parameters values to launch the algorithm
starting.values = c(c(poc, doc, runif(1), runif(1), runif(1), runif(1), runif(1), runif(1)), out.flows[1,])
starting.values
#starting.values = c(c(poc, doc, 0.75, 0.02, 0.08, 0.5, 0.44, 0.44), out.flows[1,])
starting.values = as.numeric(starting.values)
starting.values
# Lower/upper bounds contraints for each parameter.
# The optimisation algorithm needs a non-null range for all params
# => Use an epsilon to have a [poc - epsilon, poc + epsilon] range (same for the doc)
epsilon = 1E-8
lb = c(c(poc - epsilon, doc - epsilon), rep(0, nb_params - nb_fixed_entries), as.numeric(out.flows[1,]) - epsilon)
lb = as.numeric(lb)
ub = c(c(poc + epsilon, doc + epsilon, 1, 0.1, 0.1, 1, 6, 6), as.numeric(out.flows[1,]) + epsilon) # Lower bounds contraints for each parameter
# The initial parameters values to launch the algorithm
starting.values = c(c(poc, doc, runif(1), runif(1)/10, runif(1)/10, runif(1), runif(1)*6, runif(1)*6), out.flows[1,])
#starting.values = c(c(poc, doc, 0.75, 0.02, 0.08, 0.5, 0.44, 0.44), out.flows[1,])
starting.values = as.numeric(starting.values)
starting.values
# Lower/upper bounds contraints for each parameter.
# The optimisation algorithm needs a non-null range for all params
# => Use an epsilon to have a [poc - epsilon, poc + epsilon] range (same for the doc)
epsilon = 1E-8
lb = c(c(poc - epsilon, doc - epsilon), rep(0, nb_params - nb_fixed_entries), as.numeric(out.flows[1,]) - epsilon)
lb = as.numeric(lb)
ub = c(c(poc + epsilon, doc + epsilon, 1, 0.1, 0.1, 1, 6, 6), as.numeric(out.flows[1,]) + epsilon) # Lower bounds contraints for each parameter
ub = as.numeric(ub)
# Performs a gradient-free optimisation
# The goal is to minimize the distance existing between the measured
# outflows and their model counterparts
start = Sys.time()
res.station = nmkb(par = starting.values, fn = pred.error, lower=lb, upper=ub)
best.params.values
best.params.values = matrix(nb.comb.params, nb_params - nb_fixed_entries)
nb.comb.params = 100
best.params.values = matrix(nb.comb.params, nb_params - nb_fixed_entries)
best.params.values
best.params.values = matrix(NA,nb.comb.params, nb_params - nb_fixed_entries)
best.params.values
res.station$par[(nb_fixed_entries + 1):nb_params]
best.params.values[res.station$par[(nb_fixed_entries + 1):nb_params]]
best.params.values[comb,]
comb =1
best.params.values[comb,]
res.station$par[(nb_fixed_entries + 1):nb_params]
best.params.values[comb,] = res.station$par[(nb_fixed_entries + 1):nb_params]
best.params.values
nb.comb.params = 10
best.params.values = matrix(NA,nb.comb.params, nb_params - nb_fixed_entries)
for (comb in 1:nb.comb.params){
# The initial parameters values to launch the algorithm
starting.values = c(c(poc, doc, runif(1), runif(1)/10, runif(1)/10, runif(1), runif(1)*6, runif(1)*6), out.flows[1,])
#starting.values = c(c(poc, doc, 0.75, 0.02, 0.08, 0.5, 0.44, 0.44), out.flows[1,])
starting.values = as.numeric(starting.values)
# Lower/upper bounds contraints for each parameter.
# The optimisation algorithm needs a non-null range for all params
# => Use an epsilon to have a [poc - epsilon, poc + epsilon] range (same for the doc)
epsilon = 1E-8
lb = c(c(poc - epsilon, doc - epsilon), rep(0, nb_params - nb_fixed_entries), as.numeric(out.flows[1,]) - epsilon)
lb = as.numeric(lb)
ub = c(c(poc + epsilon, doc + epsilon, 1, 0.1, 0.1, 1, 6, 6), as.numeric(out.flows[1,]) + epsilon) # Lower bounds contraints for each parameter
ub = as.numeric(ub)
# Performs a gradient-free optimisation
# The goal is to minimize the distance existing between the measured
# outflows and their model counterparts
start = Sys.time()
res.station = nmkb(par = starting.values, fn = pred.error, lower=lb, upper=ub)
end  = Sys.time()
print(end - start)
best.params.values[comb,] = res.station$par[(nb_fixed_entries + 1):nb_params]
}
best.params.values
res.station
nb.comb.params = 10
best.params.values = matrix(NA,nb.comb.params, nb_params - nb_fixed_entries)
for (comb in 1:nb.comb.params){
# The initial parameters values to launch the algorithm
starting.values = c(c(poc, doc, runif(1), runif(1)/10, runif(1)/10, runif(1), runif(1)*6, runif(1)*6), out.flows[1,])
#starting.values = c(c(poc, doc, 0.75, 0.02, 0.08, 0.5, 0.44, 0.44), out.flows[1,])
starting.values = as.numeric(starting.values)
# Lower/upper bounds contraints for each parameter.
# The optimisation algorithm needs a non-null range for all params
# => Use an epsilon to have a [poc - epsilon, poc + epsilon] range (same for the doc)
epsilon = 1E-8
lb = c(c(poc - epsilon, doc - epsilon), rep(0, nb_params - nb_fixed_entries), as.numeric(out.flows[1,]) - epsilon)
lb = as.numeric(lb)
ub = c(c(poc + epsilon, doc + epsilon, 1, 0.1, 0.1, 1, 6, 6), as.numeric(out.flows[1,]) + epsilon) # Lower bounds contraints for each parameter
ub = as.numeric(ub)
# Performs a gradient-free optimisation
# The goal is to minimize the distance existing between the measured
# outflows and their model counterparts
start = Sys.time()
res.station = nmkb(par = starting.values, fn = pred.error, lower=lb, upper=ub)
end  = Sys.time()
print(end - start)
print(res.station$message)
best.params.values[comb,] = res.station$par[(nb_fixed_entries + 1):nb_params]
}
t(data.frame(best.params.values))
res = data.frame(best.params.values)
res
colnames(res) = c(labels)
res
nb.comb.params = 50
best.params.values = matrix(NA,nb.comb.params, nb_params - nb_fixed_entries)
for (comb in 1:nb.comb.params){
# The initial parameters values to launch the algorithm
starting.values = c(c(poc, doc, runif(1), runif(1)/10, runif(1)/10, runif(1), runif(1)*6, runif(1)*6), out.flows[1,])
#starting.values = c(c(poc, doc, 0.75, 0.02, 0.08, 0.5, 0.44, 0.44), out.flows[1,])
starting.values = as.numeric(starting.values)
# Lower/upper bounds contraints for each parameter.
# The optimisation algorithm needs a non-null range for all params
# => Use an epsilon to have a [poc - epsilon, poc + epsilon] range (same for the doc)
epsilon = 1E-8
lb = c(c(poc - epsilon, doc - epsilon), rep(0, nb_params - nb_fixed_entries), as.numeric(out.flows[1,]) - epsilon)
lb = as.numeric(lb)
ub = c(c(poc + epsilon, doc + epsilon, 1, 0.1, 0.1, 1, 6, 6), as.numeric(out.flows[1,]) + epsilon) # Lower bounds contraints for each parameter
ub = as.numeric(ub)
# Performs a gradient-free optimisation
# The goal is to minimize the distance existing between the measured
# outflows and their model counterparts
start = Sys.time()
res.station = nmkb(par = starting.values, fn = pred.error, lower=lb, upper=ub)
end  = Sys.time()
print(end - start)
print(res.station$message)
best.params.values[comb,] = res.station$par[(nb_fixed_entries + 1):nb_params]
}
res
nb.comb.params
res = data.frame(best.params.values)
res
colnames(res) = c(labels)
for (i in 1:nb.comb.params){
res[i]
}
res[i]
res[i,]
(nb_fixed_entries + 1):nb_params
nb_fixed_entries
for (i in 1:nb_fixed_entries){
res[,i]
}
res[,i]
for (i in 1:nb_fixed_entries){
plot(res[,i])
}
for (i in 1:nb_fixed_entries){
plot(density(res[,i]))
}
hist(res[,i])
hist(res[,i], xlab = labels[i])
hist(res[,i], xlab = labels[i], main = 'Ditribution')
hist(res[,i], xlab = labels[i], main = 'Distribution')
for (i in 1:nb_fixed_entries){
hist(res[,i], xlab = labels[i], main = 'Distribution')
}
for (i in 1:nb_fixed_entries){
hist(res[,i], xlab = labels[i], main = 'Distribution')
}
i
nb_fixed_entries
nb_fixed_params
nb.fixed.params
nb_params
for (i in 1:(n_params - nb.fixed.params)){
hist(res[,i], xlab = labels[i], main = 'Distribution')
}
for (i in 1:(nb_params - nb.fixed.params)){
hist(res[,i], xlab = labels[i], main = 'Distribution')
}
nb_params
for (i in 1:(nb_params - nb_fixed_entries)){
hist(res[,i], xlab = labels[i], main = 'Distribution')
}
for (i in 1:(nb_params - nb_fixed_entries)){
hist(res[,i], xlab = labels[i], main = 'Values estimated for 50 different initialisation parameters')
}
for (i in 1:(nb_params - nb_fixed_entries)){
hist(res[,i], xlab = labels[i], main = 'Values estimated for 50 different initialisation parameters')
}
#install.packages('dfoptim')
library(dfoptim)
data.folder = "C:/Users/rfuchs/Documents/GitHub/CarbonPump/optimisation"
res.folder = "C:/Users/rfuchs/Documents/These/Oceano/carbon_pump_abc/opt/simus/20211401/"
code.folder = "C:/Users/rfuchs/Documents/GitHub/CarbonPump/optimisation"
source(file.path(code.folder, 'model.R'))
# The weighted euclidian distance :
euc.dist <- function(x1, x2, w = 1) sqrt(rowSums((w *(x1 - x2)) ^ 2))
# The labels used for outputing
anderson_labels_txt = c('POC', 'DOC', 'psi', 'wA', 'wFL', 'alpha', 'CF_A',
'CF_FL')
# Compute the normalized error between the predicted out flows and the actual outflows
pred.error <- function(X){
models.params = X[1:8] # The 8 first parameters are the input parameters (see line 20 for the names)
out.flows = as.numeric(X[9:12]) # The three last parameters are the values of the outflows
pred = anderson(as.numeric(models.params))
w = 1 / as.numeric(out.flows) # Weight by the inverse of the flows to make all outflows comparable
d = euc.dist(matrix(pred,1), matrix(out.flows,1), w)
d
} # Watch out, the number of parameters is hard-coded for the moment in this function...
nb_params = length(anderson_labels_txt) # The number of parameters to estimate
nb_fixed_entries = length(c('poc', 'doc')) # The in situ poc and doc measures
labels = anderson_labels_txt[(nb_fixed_entries + 1):nb_params]
# Fetch the observed outflows
flows = read.csv(file.path(data.folder, 'out_flows_4flows_PAP.csv'), sep = ';')
nb_stats = length(out.flows)
nb_stats = length(flows)
names(flows) = c('Cruise', 'Station', 'Depths',
'POC net', 'DOC net', 'prod non sinking',
'prod sinking', 'resp sinking', 'resp zoo')
out.flows = flows[,c('prod non sinking', 'prod sinking',
'resp sinking', 'resp zoo')]
nb_stats
out.flows
nb_stats = length(out.flows)
nb_stats
# Get the poc and doc flows
poc = flows[1,'POC net']
doc = flows[1,'DOC net']
poc
doc
# Get the sample location meta data
cruise = flows[1,'Cruise']
station = flows[1,'Station']
station = gsub('/', '-', station)
# The initial parameters values to launch the algorithm
# They were chosen to be the ones in the Anderson and Tang or in the Giering et al. paper
starting.values = c(c(poc, doc, 0.75, 0.02, 0.08, 0.5, 0.44, 0.44), out.flows[1,])
starting.values = as.numeric(starting.values)
# Lower/upper bounds contraints for each parameter.
# The optimisation algorithm needs a non-null range for all params
# => Use an epsilon to have a [poc - epsilon, poc + epsilon] range (same for the doc)
epsilon = 1E-8
lb = c(c(poc - epsilon, doc - epsilon), rep(0, nb_params - nb_fixed_entries), as.numeric(out.flows[1,]) - epsilon)
lb = as.numeric(lb)
ub = c(c(poc + epsilon, doc + epsilon, 1, 0.1, 0.1, 1, 6, 6), as.numeric(out.flows[1,]) + epsilon) # Lower bounds contraints for each parameter
ub = as.numeric(ub)
# Performs a gradient-free optimisation
# The goal is to minimize the distance existing between the measured
# outflows and their model counterparts
start = Sys.time()
res.station = nmkb(par = starting.values, fn = pred.error, lower=lb, upper=ub)
end  = Sys.time()
print(end - start)
# Compute the error existing between flows
preds = anderson(res.station$par[1:nb_params])
flows.error = abs(as.numeric(out.flows[1,]) - preds) / as.numeric(out.flows[1,])
print(paste('flow error', flows.error)) # The errors commited on the four flows
abs(as.numeric(out.flows[1,]) - preds)
as.numeric(out.flows[1,])
preds
flows.error = round(abs(as.numeric(out.flows[1,]) - preds) / as.numeric(out.flows[1,]), 2)
print(paste('flow error', flows.error)) # The errors commited on the four flows
flows.error = round(abs(as.numeric(out.flows[1,]) - preds) / as.numeric(out.flows[1,]), 3)
print(paste('flow error', flows.error)) # The errors commited on the four flows
# save the params drawn
best.params.values = res.station$par[(nb_fixed_entries + 1):nb_params]
flows.error = abs(as.numeric(out.flows[1,]) - preds) / as.numeric(out.flows[1,])
print(paste('flow error', flows.error)) # The errors commited on the four flows
# save the params drawn
best.params.values = res.station$par[(nb_fixed_entries + 1):nb_params]
best.params.values = matrix(best.params.values, 1, nb_params - nb_fixed_entries)
res = as.numeric(c(best.params.values, c(flows.error)))
res = t(data.frame(res))
colnames(res) = c(labels, c('Error prod non sinking','Error prod sinking',
'Error resp sinking', 'Error resp zoo'))
res
nb.comb.params = 50
best.params.values = matrix(NA,nb.comb.params, nb_params - nb_fixed_entries)
for (comb in 1:nb.comb.params){
# The initial parameters values to launch the algorithm
starting.values = c(c(poc, doc, runif(1), runif(1)/10, runif(1)/10, runif(1), runif(1)*6, runif(1)*6), out.flows[1,])
#starting.values = c(c(poc, doc, 0.75, 0.02, 0.08, 0.5, 0.44, 0.44), out.flows[1,])
starting.values = as.numeric(starting.values)
# Lower/upper bounds contraints for each parameter.
# The optimisation algorithm needs a non-null range for all params
# => Use an epsilon to have a [poc - epsilon, poc + epsilon] range (same for the doc)
epsilon = 1E-8
lb = c(c(poc - epsilon, doc - epsilon), rep(0, nb_params - nb_fixed_entries), as.numeric(out.flows[1,]) - epsilon)
lb = as.numeric(lb)
ub = c(c(poc + epsilon, doc + epsilon, 1, 0.1, 0.1, 1, 6, 6), as.numeric(out.flows[1,]) + epsilon) # Lower bounds contraints for each parameter
ub = as.numeric(ub)
# Performs a gradient-free optimisation
# The goal is to minimize the distance existing between the measured
# outflows and their model counterparts
start = Sys.time()
res.station = nmkb(par = starting.values, fn = pred.error, lower=lb, upper=ub)
end  = Sys.time()
print(end - start)
print(res.station$message)
best.params.values[comb,] = res.station$par[(nb_fixed_entries + 1):nb_params]
}
res
data.frame(best.params.values)
comb
